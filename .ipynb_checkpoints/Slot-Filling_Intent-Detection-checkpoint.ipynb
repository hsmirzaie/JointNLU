{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "from model import Encoder,Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = load_data(\"dataset/atis-2.train.w-intent.iob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH=30\n",
    "train_processed, word2index, slot2index, intent2index = process_data(train_raw, LENGTH)\n",
    "index2slot = {v:k for k,v in slot2index.items()}\n",
    "index2intent = {v:k for k,v in intent2index.items()}\n",
    "index2word = {v:k for k,v in word2index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE=0.001\n",
    "EMBEDDING_SIZE=64\n",
    "HIDDEN_SIZE=32\n",
    "BATCH_SIZE=16\n",
    "EPOCHS=10\n",
    "DROPOUT_P=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(len(word2index),EMBEDDING_SIZE,HIDDEN_SIZE)\n",
    "decoder = Decoder(len(slot2index),len(intent2index),len(slot2index)//3,HIDDEN_SIZE*2, dropout_p=DROPOUT_P)\n",
    "\n",
    "encoder.init_weights()\n",
    "decoder.init_weights()\n",
    "\n",
    "loss_function_1 = nn.CrossEntropyLoss(ignore_index=0)\n",
    "loss_function_2 = nn.CrossEntropyLoss()\n",
    "enc_optim= optim.Adam(encoder.parameters(), lr=LEARNING_RATE)\n",
    "dec_optim = optim.Adam(decoder.parameters(),lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ho3in\\Anaconda3\\envs\\Deep-Learning-Ng\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "C:\\Users\\Ho3in\\Anaconda3\\envs\\Deep-Learning-Ng\\lib\\site-packages\\ipykernel_launcher.py:61: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0  batch 0  :  7.9664974\n",
      "EPOCH 0  batch 100  :  4.1804395\n",
      "EPOCH 0  batch 200  :  2.634928\n",
      "EPOCH 1  batch 0  :  2.244953\n",
      "EPOCH 1  batch 100  :  2.1919923\n",
      "EPOCH 1  batch 200  :  1.9852215\n",
      "EPOCH 2  batch 0  :  2.1585941\n",
      "EPOCH 2  batch 100  :  1.7021719\n",
      "EPOCH 2  batch 200  :  1.4902431\n",
      "EPOCH 3  batch 0  :  0.89181226\n",
      "EPOCH 3  batch 100  :  1.0672523\n",
      "EPOCH 3  batch 200  :  0.998114\n",
      "EPOCH 4  batch 0  :  0.8869954\n",
      "EPOCH 4  batch 100  :  0.7939249\n",
      "EPOCH 4  batch 200  :  0.8265474\n",
      "EPOCH 5  batch 0  :  1.2666262\n",
      "EPOCH 5  batch 100  :  0.67856055\n",
      "EPOCH 5  batch 200  :  0.6208588\n",
      "EPOCH 6  batch 0  :  0.68808115\n",
      "EPOCH 6  batch 100  :  0.5541038\n",
      "EPOCH 6  batch 200  :  0.48256585\n",
      "EPOCH 7  batch 0  :  0.15562415\n",
      "EPOCH 7  batch 100  :  0.46624243\n",
      "EPOCH 7  batch 200  :  0.41408074\n",
      "EPOCH 8  batch 0  :  0.3710662\n",
      "EPOCH 8  batch 100  :  0.37416816\n",
      "EPOCH 8  batch 200  :  0.37432072\n",
      "EPOCH 9  batch 0  :  0.40323794\n",
      "EPOCH 9  batch 100  :  0.30311328\n",
      "EPOCH 9  batch 200  :  0.3096535\n"
     ]
    }
   ],
   "source": [
    "intent_acc = []\n",
    "slot_acc = []\n",
    "for epoch in range(EPOCHS):\n",
    "    losses=[]\n",
    "    intent_truly_labeled = 0\n",
    "    intent_mislabeled = 0\n",
    "    slot_truly_labeled = 0\n",
    "    slot_mislabeled = 0\n",
    "    for i, batch in enumerate(getBatch(BATCH_SIZE,train_processed)):\n",
    "        x,y_1,y_2 = zip(*batch)\n",
    "        x = torch.cat(x)\n",
    "        slot_target = torch.cat(y_1)\n",
    "        intent_target = torch.cat(y_2)\n",
    "        x_mask = torch.cat([Variable(torch.BoolTensor(tuple(map(lambda s: s ==0, t.data)))) for t in x]).view(BATCH_SIZE,-1)\n",
    "        y_1_mask = torch.cat([Variable(torch.BoolTensor(tuple(map(lambda s: s ==0, t.data)))) for t in slot_target]).view(BATCH_SIZE,-1)\n",
    " \n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "\n",
    "        output, hidden_c = encoder(x,x_mask) # hidden_c : last hidden state of encoder to start decoder\n",
    "        \n",
    "        start_decode = Variable(torch.LongTensor([[word2index['<SOS>']]*BATCH_SIZE])).transpose(1,0)\n",
    "        # start_decode.shape = torch.Size([16, 1]) ==> start_decode = [2, 2, 2, 2, ..., 2] (word2index['<SOS>'] = 2)\n",
    "        slot_score, intent_score = decoder(start_decode,hidden_c,output,x_mask)\n",
    "\n",
    "        #print(slot_target.size()) ===> torch.Size([16, 50])\n",
    "        #print(slot_score.size()) ===> torch.Size([800, 122]) (800 = B*T = 16*50)\n",
    "        #print(intent_score.size()) ===> torch.Size([16, 22])\n",
    "\n",
    "        #print(intent_score)\n",
    "        _,intent_predicted = torch.max(intent_score,1)\n",
    "        \n",
    "        intent_truly_labeled += sum(intent_target == intent_predicted).item()\n",
    "        intent_mislabeled += sum(intent_target != intent_predicted).item()\n",
    "        \n",
    "                 \n",
    "        _,slot_predicted = torch.max(slot_score,1)\n",
    "\n",
    "        #print(slot_target.size())\n",
    "        true = 0\n",
    "        false = 0\n",
    "        for j in range(len(slot_target.view(-1))):\n",
    "            if slot_target.view(-1)[j] != 0:\n",
    "                if slot_target.view(-1)[j] == slot_predicted[j].item():\n",
    "                    true += 1\n",
    "                else:\n",
    "                    false += 1\n",
    "\n",
    "        slot_truly_labeled += true\n",
    "        slot_mislabeled += false\n",
    "        \n",
    "        \n",
    "        loss_1 = loss_function_1(slot_score,slot_target.view(-1))\n",
    "        loss_2 = loss_function_2(intent_score,intent_target)\n",
    "\n",
    "        loss = loss_1+loss_2\n",
    "        losses.append(loss.data.numpy())\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm(encoder.parameters(), 5.0)\n",
    "        torch.nn.utils.clip_grad_norm(decoder.parameters(), 5.0)\n",
    "\n",
    "        enc_optim.step()\n",
    "        dec_optim.step()\n",
    "\n",
    "        if i % 100==0:\n",
    "            print(\"EPOCH\",epoch,\" batch\",i,\" : \",np.mean(losses))\n",
    "            \n",
    "            losses=[]\n",
    "                 \n",
    "    intent_acc.append(intent_truly_labeled / (intent_truly_labeled + intent_mislabeled))\n",
    "    slot_acc.append(slot_truly_labeled / (slot_truly_labeled + slot_mislabeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.7155017921146953,\n",
       "  0.8362455197132617,\n",
       "  0.8891129032258065,\n",
       "  0.9023297491039427,\n",
       "  0.9222670250896058,\n",
       "  0.9310035842293907,\n",
       "  0.9372759856630825,\n",
       "  0.9498207885304659,\n",
       "  0.9614695340501792,\n",
       "  0.9670698924731183],\n",
       " [0.6203436398749677,\n",
       "  0.6601539961401485,\n",
       "  0.7700356055934597,\n",
       "  0.8478100809901896,\n",
       "  0.884009233095873,\n",
       "  0.9107050439906047,\n",
       "  0.9297620942075111,\n",
       "  0.9421313334261672,\n",
       "  0.9499492729117349,\n",
       "  0.9583416225679385])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_acc, slot_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_intent_acc = intent_acc\n",
    "train_slot_acc = slot_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot accuracy vs epoch graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(train_intent_acc, label='train_intent_acc')\n",
    "plt.plot(train_slot_acc, label='train_slot_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model's Performance on the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence:    which airlines fly from boston to washington dc via other cities\n",
      "\n",
      "Slot Targets:    O O O O B-fromloc.city_name O B-toloc.city_name B-toloc.state_code O O O\n",
      "Slot Predictions:    O O O O B-fromloc.city_name O B-toloc.city_name B-toloc.state_code O O O\n",
      "\n",
      "Intent Targets:    atis_airline\n",
      "Intent Predictions:    atis_airline\n"
     ]
    }
   ],
   "source": [
    "index = random.choice(range(len(train_processed)))\n",
    "\n",
    "sample = train_raw[index][0]\n",
    "train_in = prepare_sequence(sample,word2index)\n",
    "\n",
    "train_mask = Variable(torch.BoolTensor(tuple(map(lambda s: s ==0, train_in.data)))).view(1,-1)\n",
    "start_decode = Variable(torch.LongTensor([[word2index['<SOS>']]*1])).transpose(1,0)\n",
    "\n",
    "output, hidden_c = encoder(train_in.unsqueeze(0),train_mask.unsqueeze(0))\n",
    "\n",
    "slot_score, intent_score = decoder(start_decode,hidden_c,output,train_mask)\n",
    "\n",
    "v,i = torch.max(slot_score,1)\n",
    "\n",
    "print(\"Input Sentence:   \",*train_raw[index][0])\n",
    "print()\n",
    "print(\"Slot Targets:   \",*train_raw[index][1])\n",
    "print(\"Slot Predictions:   \",*list(map(lambda ii:index2slot[ii],i.data.tolist())))\n",
    "\n",
    "print()\n",
    "v,i = torch.max(intent_score,1)\n",
    "print(\"Intent Targets:   \",train_raw[index][2])\n",
    "print(\"Intent Predictions:   \",index2intent[i.data.tolist()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model's Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(decoder.state_dict(),'model/jointnlu-decoder.pkl')\n",
    "torch.save(encoder.state_dict(),'model/jointnlu-encoder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model's parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder2 = Encoder(len(word2index),EMBEDDING_SIZE,HIDDEN_SIZE)\n",
    "decoder2 = Decoder(len(slot2index),len(intent2index),len(slot2index)//3,HIDDEN_SIZE*2)\n",
    "\n",
    "encoder2.load_state_dict(torch.load('model/jointnlu-encoder.pkl'))\n",
    "decoder2.load_state_dict(torch.load('model/jointnlu-decoder.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Testing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw = load_data(\"dataset/atis-2.dev.w-intent.iob\")\n",
    "test_processed = test_process(test_raw, word2index, slot2index, intent2index, LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_truly_labeled = 0\n",
    "intent_mislabeled = 0\n",
    "slot_truly_labeled = 0\n",
    "slot_mislabeled = 0\n",
    "\n",
    "for i, batch in enumerate(getBatch(BATCH_SIZE,test_processed, Shuffle = False)):\n",
    "    x,y_1,y_2 = zip(*batch)\n",
    "    x = torch.cat(x)\n",
    "    slot_target = torch.cat(y_1)\n",
    "    intent_target = torch.cat(y_2)\n",
    "    x_mask = torch.cat([Variable(torch.BoolTensor(tuple(map(lambda s: s ==0, t.data)))) for t in x]).view(BATCH_SIZE,-1)\n",
    "    y_1_mask = torch.cat([Variable(torch.BoolTensor(tuple(map(lambda s: s ==0, t.data)))) for t in slot_target]).view(BATCH_SIZE,-1)\n",
    "    \n",
    "    start_decode = Variable(torch.LongTensor([[word2index['<SOS>']]*BATCH_SIZE])).transpose(1,0)\n",
    "    \n",
    "    output, hidden_c = encoder2(x,x_mask)\n",
    "\n",
    "    slot_score, intent_score = decoder2(start_decode,hidden_c,output,x_mask)\n",
    "    \n",
    "    _,intent_predicted = torch.max(intent_score,1)\n",
    "    \n",
    "    intent_truly_labeled += sum(intent_target == intent_predicted).item()\n",
    "    intent_mislabeled += sum(intent_target != intent_predicted).item()\n",
    "    \n",
    "    _,slot_predicted = torch.max(slot_score,1)\n",
    "\n",
    "    #print(slot_target.size())\n",
    "    true = 0\n",
    "    false = 0\n",
    "    for j in range(len(slot_target.view(-1))):\n",
    "        if slot_target.view(-1)[j] != 0:\n",
    "            if slot_target.view(-1)[j] == slot_predicted[j].item():\n",
    "                true += 1\n",
    "            else:\n",
    "                false += 1\n",
    "\n",
    "    slot_truly_labeled += true\n",
    "    slot_mislabeled += false\n",
    "\n",
    "    \n",
    "    #print(slot_predicted)\n",
    "\n",
    "    #print(slot_target.view(-1))\n",
    "    #print()\n",
    "        \n",
    "intent_acc = intent_truly_labeled / (intent_truly_labeled + intent_mislabeled)\n",
    "slot_acc = slot_truly_labeled / (slot_truly_labeled + slot_mislabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9415322580645161, 0.9514958399716764)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_acc, slot_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_intent_acc = intent_acc\n",
    "test_slot_acc  = slot_acc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model's Performance on the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence:    what is the earliest flight arriving in charlotte from st. louis on friday\n",
      "\n",
      "Slot Targets:    O O O B-flight_mod O O O B-toloc.city_name O B-fromloc.city_name I-fromloc.city_name O B-arrive_date.day_name\n",
      "Slot Predictions:    O O O B-flight_mod O O B-fromloc.city_name O B-toloc.city_name B-toloc.state_name O B-toloc.city_name\n",
      "\n",
      "Intent Targets:    atis_flight\n",
      "Intent Predictions:    atis_flight\n"
     ]
    }
   ],
   "source": [
    "index = random.choice(range(len(test_processed)))\n",
    "\n",
    "#index = 0\n",
    "sample = test_raw[index][0]\n",
    "test_in = prepare_sequence(sample,word2index)\n",
    "\n",
    "test_mask = Variable(torch.BoolTensor(tuple(map(lambda s: s ==0, test_in.data)))).view(1,-1)\n",
    "start_decode = Variable(torch.LongTensor([[word2index['<SOS>']]*1])).transpose(1,0)\n",
    "\n",
    "output, hidden_c = encoder2(test_in.unsqueeze(0),test_mask.unsqueeze(0))\n",
    "\n",
    "slot_score, intent_score = decoder2(start_decode,hidden_c,output,test_mask)\n",
    "\n",
    "v,i = torch.max(slot_score,1)\n",
    "\n",
    "print(\"Input Sentence:   \",*train_raw[index][0])\n",
    "print()\n",
    "print(\"Slot Targets:   \",*train_raw[index][1])\n",
    "print(\"Slot Predictions:   \",*list(map(lambda ii:index2slot[ii],i.data.tolist())))\n",
    "\n",
    "print()\n",
    "v,i = torch.max(intent_score,1)\n",
    "print(\"Intent Targets:   \",train_raw[index][2])\n",
    "print(\"Intent Predictions:   \",index2intent[i.data.tolist()[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
